{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "120bf77e-cb8c-4098-ad44-d2ea8fa7cf1a",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabcc5de-d7c4-47e9-968c-6e751c3bef97",
   "metadata": {},
   "source": [
    "### Load data & imports + Environment check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91d2c65-c7a6-49e1-84ee-b99756a922b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "print(\"Environment check:\")\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"XGBoost:\", xgb.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad00aa9f-11ee-4f71-91b3-7f6286f613a1",
   "metadata": {},
   "source": [
    "### Load Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d55ffe-94ec-40bc-ba65-9ef7d51e4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "if os.path.basename(cwd) == \"notebooks\":\n",
    "    project_root = os.path.dirname(cwd)\n",
    "else:\n",
    "    project_root = cwd\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "\n",
    "data_dir = os.path.join(project_root, \"data\", \"processed\")\n",
    "train_path = os.path.join(data_dir, \"train.csv\")\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    raise FileNotFoundError(f\"Missing {train_path}. Run 01_preprocessing.ipynb first.\")\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a91828-19c6-40e9-b9d3-33df004c3b5c",
   "metadata": {},
   "source": [
    "### Build feature matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9896f94-bd00-4803-81c4-4cd3ac9522e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"label\" not in train_df.columns:\n",
    "    raise KeyError(\"Expected 'label' column in train.csv\")\n",
    "\n",
    "y_train = train_df[\"label\"].astype(int)\n",
    "\n",
    "drop_cols = [\"label\"]\n",
    "if \"insider\" in train_df.columns:\n",
    "    drop_cols.append(\"insider\")\n",
    "\n",
    "X_train = train_df.drop(columns=drop_cols)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd66994-b14d-4636-8a0d-ce063054d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y_train)\n",
    "n_neg = counter[0]\n",
    "n_pos = counter[1]\n",
    "scale_pos_weight = n_neg / n_pos\n",
    "\n",
    "print(\"Class counts:\", counter)\n",
    "print(f\"scale_pos_weight: {scale_pos_weight:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b43424-31ca-4dc6-8c9f-08e793707cb0",
   "metadata": {},
   "source": [
    "### Define Base XGBoost Model and Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b9268d-1ac0-4b11-9c6b-70b5dd9dda4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_base = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "spw = scale_pos_weight\n",
    "param_dist = {\n",
    "    \"learning_rate\": [0.03, 0.05, 0.07, 0.1],\n",
    "    \"max_depth\": [3, 4, 5, 6],\n",
    "    \"min_child_weight\": [1, 3, 5, 7],\n",
    "    \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.7, 0.8, 1.0],\n",
    "    \"n_estimators\": [300, 400, 500, 600, 700],\n",
    "    \"gamma\": [0, 0.5, 1, 3],\n",
    "    \"reg_lambda\": [1, 3, 5, 10],\n",
    "    \"reg_alpha\": [0, 0.1, 0.5, 1.0],\n",
    "    \"scale_pos_weight\": [\n",
    "        0.5 * spw,\n",
    "        0.75 * spw,\n",
    "        1.0 * spw,\n",
    "        1.25 * spw,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbea7e1-ea0f-448b-948e-4328d79f8de7",
   "metadata": {},
   "source": [
    "### Setup Randomized CV Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065239b3-7cbc-478d-ab25-5eead78aa219",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "f1_scorer = make_scorer(f1_score)\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=xgb_base,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=40,              \n",
    "    scoring=f1_scorer,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9a122-30dc-47e9-a1e5-4e928a3fd230",
   "metadata": {},
   "source": [
    "### Run Tuning\n",
    "This one will take a while too, as it has to evaluate 200 fits. Again, don't be afraid!\n",
    "\n",
    "**If you don't want to wait, you can hardcode the best params provided in the README**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ba057-9a8e-42fe-8ae3-051621a5fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best mean CV F1:\", search.best_score_)\n",
    "print(\"Best params:\")\n",
    "search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5084ef07-a901-4f90-9d43-e2c1f2c52e08",
   "metadata": {},
   "source": [
    "### Train tuned model using best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ccd0a3-c5c2-44be-8095-65e3f4dfb392",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = search.best_params_\n",
    "\n",
    "#to hard code params\n",
    "'''best_params = {'subsample': 0.7,\n",
    " 'scale_pos_weight': 158.325,\n",
    " 'reg_lambda': 3,\n",
    " 'reg_alpha': 0,\n",
    " 'n_estimators': 300,\n",
    " 'min_child_weight': 1,\n",
    " 'max_depth': 6,\n",
    " 'learning_rate': 0.1,\n",
    " 'gamma': 0,\n",
    " 'colsample_bytree': 0.8}\n",
    " '''\n",
    "xgb_tuned = xgb.XGBClassifier(\n",
    "    **best_params,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "xgb_tuned.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f226d84d-34f2-4218-9f55-729bb7255bb5",
   "metadata": {},
   "source": [
    "### Save tuned model & Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f3b2f3-8bfc-44e8-a20a-2711ab5203fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = os.path.join(project_root, \"models\")\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "model_path = os.path.join(models_dir, \"xgb_tuned_model.joblib\")\n",
    "joblib.dump(xgb_tuned, model_path)\n",
    "\n",
    "print(\"Saved tuned model to:\", model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f18437-d277-4a09-85fb-d58832d7e51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "params_path = os.path.join(models_dir, \"xgb_best_params.json\")\n",
    "with open(params_path, \"w\") as f:\n",
    "    json.dump(best_params, f, indent=4)\n",
    "\n",
    "print(\"Saved best params to:\", params_path)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92dc5a3-0da4-40be-b8c5-077986968353",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this notebook, we tuned the XGBoost classifier using a 20-iteration\n",
    "`RandomizedSearchCV` over a 5-fold Stratified Cross-Validation split on the\n",
    "training data.\n",
    "\n",
    "The search optimized for F1 score, which balances precision and recall on\n",
    "the highly imbalanced CERT insider-threat dataset. The best parameters were then used to train a final, tuned model on the training set.\n",
    "\n",
    "The tuned model and its hyperparameters are saved to:\n",
    "\n",
    "- `models/xgb_tuned_model.joblib`\n",
    "- `models/xgb_best_params.json`\n",
    "\n",
    "These will be used in:\n",
    "\n",
    "- Notebook 04 for feature importance and feature selection\n",
    "- Notebook 05 for threshold evaluation and calibration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "certml",
   "language": "python",
   "name": "certml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
