{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f828617-1ced-47fe-9a15-418d2dc4f8c2",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e178d-0aa4-426d-8df8-b2394fbdb50c",
   "metadata": {},
   "source": [
    "### Environment and File Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5b0f0d-beae-4dff-a040-1f77b24cfaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment check:\n",
      "Python: 3.10.18 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 13:08:55) [MSC v.1929 64 bit (AMD64)]\n",
      "Pandas: 2.3.3\n",
      "NumPy: 2.2.6\n",
      "scikit-learn: 1.7.2\n",
      "imbalanced-learn: 0.14.0\n",
      "XGBoost: 3.0.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"Environment check:\")\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "print(\"NumPy:\", np.__version__)\n",
    "import sklearn, imblearn\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"imbalanced-learn:\", imblearn.__version__)\n",
    "print(\"XGBoost:\", xgb.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba1d67-6161-4ed5-a2a1-7f23288561dd",
   "metadata": {},
   "source": [
    "### Load Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace42d0d-fee5-4ebf-a908-afd4e7868577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\MayaW\\OneDrive - North Dakota University System\\UND 2025-2026\\CS492 - Senior Project\\Final Notebooks\n",
      "Found training data: C:\\Users\\MayaW\\OneDrive - North Dakota University System\\UND 2025-2026\\CS492 - Senior Project\\Final Notebooks\\data\\processed\\train.csv\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "# If user started Jupyter inside notebooks/, move one level up\n",
    "if os.path.basename(cwd) == \"notebooks\":\n",
    "    project_root = os.path.dirname(cwd)\n",
    "else:\n",
    "    project_root = cwd\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "data_dir = os.path.join(project_root, \"data\")\n",
    "processed_dir = os.path.join(data_dir, \"processed\")\n",
    "train_path = os.path.join(processed_dir, \"train.csv\")\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing {train_path}. \"\n",
    "        \"Make sure you ran 01_preprocessing.ipynb successfully first.\"\n",
    "    )\n",
    "\n",
    "print(f\"Found training data: {train_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "841ad972-0713-48e2-a546-3bc76034f37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (40299, 665)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>b_unit</th>\n",
       "      <th>f_unit</th>\n",
       "      <th>dept</th>\n",
       "      <th>team</th>\n",
       "      <th>ITAdmin</th>\n",
       "      <th>O</th>\n",
       "      <th>C</th>\n",
       "      <th>E</th>\n",
       "      <th>A</th>\n",
       "      <th>...</th>\n",
       "      <th>weekendhttp_hackf_mean_url_len</th>\n",
       "      <th>weekendhttp_hackf_mean_url_depth</th>\n",
       "      <th>weekendhttp_hackf_mean_http_c_len</th>\n",
       "      <th>weekendhttp_hackf_mean_http_c_nwords</th>\n",
       "      <th>weekendhttp_hackf_n-pc0</th>\n",
       "      <th>weekendhttp_hackf_n-pc1</th>\n",
       "      <th>weekendhttp_hackf_n-pc2</th>\n",
       "      <th>weekendhttp_hackf_n-pc3</th>\n",
       "      <th>insider</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 665 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   role  b_unit  f_unit  dept  team  ITAdmin   O   C   E   A  ...  \\\n",
       "0    39       0       4    15    29        0  46  20  32  26  ...   \n",
       "1    39       0       4    15     4        0  36  41  45  19  ...   \n",
       "2    39       0       4    15    11        0  11  20  39  20  ...   \n",
       "3    39       0       1    14    37        0  26  23  16  30  ...   \n",
       "4    24       0       1     5    28        0  27  35  20  36  ...   \n",
       "\n",
       "   weekendhttp_hackf_mean_url_len  weekendhttp_hackf_mean_url_depth  \\\n",
       "0                               0                                 0   \n",
       "1                               0                                 0   \n",
       "2                               0                                 0   \n",
       "3                               0                                 0   \n",
       "4                               0                                 0   \n",
       "\n",
       "   weekendhttp_hackf_mean_http_c_len  weekendhttp_hackf_mean_http_c_nwords  \\\n",
       "0                                  0                                     0   \n",
       "1                                  0                                     0   \n",
       "2                                  0                                     0   \n",
       "3                                  0                                     0   \n",
       "4                                  0                                     0   \n",
       "\n",
       "   weekendhttp_hackf_n-pc0  weekendhttp_hackf_n-pc1  weekendhttp_hackf_n-pc2  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "\n",
       "   weekendhttp_hackf_n-pc3  insider  label  \n",
       "0                        0        0      0  \n",
       "1                        0        0      0  \n",
       "2                        0        0      0  \n",
       "3                        0        0      0  \n",
       "4                        0        0      0  \n",
       "\n",
       "[5 rows x 665 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecd0367-608d-4393-814d-60b5bcd2a820",
   "metadata": {},
   "source": [
    "### Separate Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310404ea-1752-48ed-b039-dcc0092c1ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (40299, 663)\n",
      "Label vector shape: (40299,)\n",
      "\n",
      "Label distribution (train):\n",
      "label\n",
      "0    40109\n",
      "1      190\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if \"label\" not in train_df.columns:\n",
    "    raise KeyError(\"Expected column 'label' in train.csv (binary insider / normal).\")\n",
    "\n",
    "# Features: drop 'label' and 'insider' (scenario ID) if present\n",
    "drop_cols = [\"label\"]\n",
    "if \"insider\" in train_df.columns:\n",
    "    drop_cols.append(\"insider\")\n",
    "\n",
    "X = train_df.drop(columns=drop_cols)\n",
    "y = train_df[\"label\"].astype(int)\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Label vector shape:\", y.shape)\n",
    "print(\"\\nLabel distribution (train):\")\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985fe708-8e66-46d6-ac8b-48b48af3528f",
   "metadata": {},
   "source": [
    "### Define Models and SMOTE pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c067d1e-a6b7-42d7-8870-fd8ad1c31052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight for XGBoost: 211.10\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "\n",
    "def smote_pipeline(model, sampling=0.3, scale=False):\n",
    "    \"\"\"\n",
    "    Create a pipeline with SMOTE + optional scaling for models\n",
    "    that benefit from oversampling (Logistic Regression, SVM).\n",
    "    \"\"\"\n",
    "    steps = [('smote', SMOTE(random_state=42, sampling_strategy=sampling))]\n",
    "    if scale:\n",
    "        steps.append(('scale', StandardScaler()))\n",
    "    steps.append(('model', model))\n",
    "    return ImbPipeline(steps=steps)\n",
    "    \n",
    "# Define Models\n",
    "models = {}\n",
    "\n",
    "# 1) Logistic Regression + SMOTE + scaling\n",
    "models[\"LogReg + SMOTE\"] = smote_pipeline(\n",
    "    LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "        max_iter=500,\n",
    "        tol=1e-3,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    ),\n",
    "    sampling=0.3,\n",
    "    scale=True\n",
    ")\n",
    "\n",
    "# 2) Linear SVM + SMOTE + scaling\n",
    "models[\"Linear SVM + SMOTE\"] = smote_pipeline(\n",
    "    LinearSVC(\n",
    "        class_weight='balanced',\n",
    "        max_iter=5000,\n",
    "        tol=1e-3,\n",
    "        random_state=42\n",
    "    ),\n",
    "    sampling=0.3,\n",
    "    scale=True\n",
    ")\n",
    "\n",
    "# 3) Random Forest (NO SMOTE, uses class_weight)\n",
    "models[\"Random Forest (balanced)\"] = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4) XGBoost (NO SMOTE, uses scale_pos_weight)\n",
    "counter = Counter(y) \n",
    "scale_pos_weight = counter[0] / counter[1]\n",
    "print(f\"scale_pos_weight for XGBoost: {scale_pos_weight:.2f}\")\n",
    "\n",
    "models[\"XGBoost (no SMOTE)\"] = xgb.XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60a638e-c6b9-48a1-aca3-fb4411b04fd7",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76bf77f2-e5d8-4c7f-b7ab-3ad404fa45d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Evaluating: LogReg + SMOTE ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scoring = {\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\",\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== Evaluating: {name} ===\")\n",
    "    cv_result = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False\n",
    "    )\n",
    "    \n",
    "    precision_mean = cv_result[\"test_precision\"].mean()\n",
    "    recall_mean    = cv_result[\"test_recall\"].mean()\n",
    "    f1_mean        = cv_result[\"test_f1\"].mean()\n",
    "    \n",
    "    precision_std = cv_result[\"test_precision\"].std()\n",
    "    recall_std    = cv_result[\"test_recall\"].std()\n",
    "    f1_std        = cv_result[\"test_f1\"].std()\n",
    "    \n",
    "    print(f\"Precision: {precision_mean:.4f} ± {precision_std:.4f}\")\n",
    "    print(f\"Recall:    {recall_mean:.4f} ± {recall_std:.4f}\")\n",
    "    print(f\"F1-score:  {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "    \n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"precision_mean\": precision_mean,\n",
    "        \"precision_std\": precision_std,\n",
    "        \"recall_mean\": recall_mean,\n",
    "        \"recall_std\": recall_std,\n",
    "        \"f1_mean\": f1_mean,\n",
    "        \"f1_std\": f1_std,\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f510a-71b3-4901-9c2f-2875456b84a4",
   "metadata": {},
   "source": [
    "# Key Observations\n",
    "### Logistic Regression + SMOTE\n",
    "\n",
    "Very high recall (~0.85)\n",
    "\n",
    "Extremely low precision (~0.06)\n",
    "\n",
    "Produces too many false positives to be operationally useful\n",
    "\n",
    "### Linear SVM + SMOTE\n",
    "\n",
    "More balanced than logistic regression\n",
    "\n",
    "Moderate precision and recall\n",
    "\n",
    "Still underperforms compared to tree-based models\n",
    "\n",
    "### Random Forest + SMOTE\n",
    "\n",
    "Good precision (~0.54)\n",
    "\n",
    "Lower recall (~0.40)\n",
    "\n",
    "Performance strongly affected by oversampling\n",
    "\n",
    "### XGBoost (no SMOTE)\n",
    "\n",
    "Best overall performance\n",
    "\n",
    "Highest F1-score (~0.71)\n",
    "\n",
    "Strong precision and recall balance\n",
    "\n",
    "Naturally handles imbalanced data with scale_pos_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb4c002-0d84-40dc-ba20-d288ac783afa",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "XGBoost is the strongest baseline model and is selected as the primary candidate for further optimization.\n",
    "Its superior performance, stability under class imbalance, and flexible tuning options make it the best foundation for the next stage of the pipeline.\n",
    "\n",
    "The next notebook (03_modelTuning) will focus on hyperparameter optimization using RandomizedSearchCV to further improve performance before feature selection and threshold calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa64c36b-41dd-4d2c-951b-91b3861d3a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "certml",
   "language": "python",
   "name": "certml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
